{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whole brain data processing\n",
    "\n",
    "### Making mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from cellProcessing import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def force_bkill_dask():\n",
    "    try:\n",
    "        get_ipython().run_cell_magic('bash', '', 'bkill -q normal 0\\n')\n",
    "    except:\n",
    "        get_ipython().run_cell_magic('bash', '', 'bjobs\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environments\n",
    "\n",
    "* Install `fish_proc` from github https://github.com/zqwei/fish_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## STEP 1: specify data and save path\n",
    "dir_root = '/groups/ahrens/ahrenslab/jing/giving_up/20190219/fish2/7dpf-huc_gcamp7ff_gfap_rgeco-GU_slow_fwd-fish02-exp02_20190219_174013/im'\n",
    "# save_root = '/nrs/ahrens/jing/20190219/fish2/7dpf-huc_gcamp7ff_gfap_rgeco-GU_slow_fwd-fish02-exp02_20190219_174013/processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set save folder to Ziqiang's folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_root = './processed'\n",
    "if not os.path.exists(save_root):\n",
    "    os.makedirs(save_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preproecssing\n",
    "This will generate the follow files at `save_root` folder\n",
    "* `motion_fix_.h5` -- reference image\n",
    "* `trans_affs.npy` -- affine transform\n",
    "* `Y_2dnorm_ave.h5` -- average image after detrend\n",
    "* `local_pca_data.zarr` -- local pca denoised image (This might be used a x4 file size comparing to the raw data), which can be removed afterwards\n",
    "\n",
    "### Notes\n",
    "* ZW -- (Rechunk from image to time) I used 500 cores, and it broke down several times, but it is still working (41 minutes on rechunks), try at least 700 cores as a start\n",
    "* ZW -- (later steps) I used number of blocks + 1 as number of cores (this can be precomputed)\n",
    "* ZW -- computation time of baseline linearly increases with x, y, and baseline_window in each block (about 30 min for 256 x 256 x 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nsplit = 32\n",
    "baseline_percentile = 20  \n",
    "baseline_window = 400   # number of frames\n",
    "numCores = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "preprocessing(dir_root, save_root, numCores=numCores, window=baseline_window, percentile=baseline_percentile, nsplit=nsplit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job <56345649> is being terminated\n",
      "Job <56346674> is being terminated\n"
     ]
    }
   ],
   "source": [
    "force_bkill_dask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask\n",
    "Making a mask for data to decrease the number of computation in demix\n",
    "* remove low intensity pixel\n",
    "* remove low snr pixel\n",
    "* remove low local pixel correlation pixels\n",
    "\n",
    "This will generate the follow files at `save_root` folder\n",
    "* `mask_map.h5` -- mask\n",
    "* `local_correlation_map.h5` -- local correlation\n",
    "* `masked_local_pca_data.zarr` -- df/f computation\n",
    "* `masked_downsampled_local_pca_data.zarr` -- downsampled in time -> used for cell segmentation, which can be removed afterwards\n",
    "\n",
    "### Note\n",
    "* ZW -- intensity_percentile can be experimented using notebook `Test_for_pipeline_mask`\n",
    "* ZW -- I used 50% for examplary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import scipy.ndimage.filters as sfilter\n",
    "from utils import intesity_mask\n",
    "# Y_d_ave_ = zarr.open(f'{save_root}/Y_ave.zarr', 'r')\n",
    "Y_d_ave_ = zarr.open(f'{save_root}/Y_max.zarr', 'r')\n",
    "intensity_percentile = np.ones(Y_d_ave_.shape[0])*50\n",
    "intensity_percentile[17] = 70\n",
    "intensity_percentile[18] = 80\n",
    "intensity_percentile[19] = 90\n",
    "intensity_percentile[20] = 95\n",
    "mask = np.zeros(Y_d_ave_.shape).astype('bool')\n",
    "for n, n_ave_ in enumerate(Y_d_ave_):\n",
    "    mask_ = intesity_mask(n_ave_, intensity_percentile[n])\n",
    "    mask_median = sfilter.median_filter(mask_.squeeze().astype('int'), size=7) == 1\n",
    "    mask[n] = mask_ & mask_median[:, :, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, n_ave_ in enumerate(Y_d_ave_):\n",
    "    int_ = intensity_percentile[n]\n",
    "    _ = n_ave_.copy()\n",
    "    _[~mask[n]] = np.nan\n",
    "    plt.imshow(_.squeeze(), vmax=np.percentile(n_ave_, max(int_+3, 90)), vmin=np.percentile(n_ave_, int_))\n",
    "    # plt.imshow(mask[n].squeeze(), cmap='gray', alpha=0.7)\n",
    "    plt.title(n)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z, x, y, _ = mask.shape\n",
    "cluster, client = fdask.setup_workers(1)\n",
    "mask = da.from_array(mask, chunks=(1, x//nsplit, y//nsplit, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_sum = mask.map_blocks(lambda v:v.sum()*np.ones((1, x//nsplit, y//nsplit, 1))).compute()>2500\n",
    "for n, n_ave_ in enumerate(Y_d_ave_):\n",
    "    int_ = intensity_percentile[n]\n",
    "    _ = n_ave_.copy()\n",
    "    _[~mask[n]] = np.nan\n",
    "    plt.imshow(_.squeeze(), vmax=np.percentile(n_ave_, max(int_+3, 90)), vmin=np.percentile(n_ave_, int_))\n",
    "    plt.imshow(mask_sum[n].squeeze(), cmap='gray', alpha=0.3)\n",
    "    plt.title(n)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.from_array((mask.compute() & mask_sum), chunks=(1, x//nsplit, y//nsplit, -1)).to_zarr(f'{save_root}/mask_map.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = da.from_zarr(f'{save_root}/mask_map.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, n_ave_ in enumerate(Y_d_ave_):\n",
    "    int_ = intensity_percentile[n]\n",
    "    _ = n_ave_.copy()\n",
    "    _[~mask[n]] = np.nan\n",
    "    plt.imshow(_.squeeze(), vmax=np.percentile(n_ave_, max(int_+3, 90)), vmin=np.percentile(n_ave_, int_))\n",
    "    plt.title(n)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.stop_all_jobs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No unfinished job found in queue <normal>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JOBID      USER    STAT  QUEUE      FROM_HOST   EXEC_HOST   JOB_NAME   SUBMIT_TIME\n",
      "56331524   weiz    RUN   interactiv c11u24      h11u02      /bin/bash  Mar 12 12:43\n",
      "56337811   weiz    RUN   interactiv c11u24      h11u02      /bin/bash  Mar 12 14:37\n"
     ]
    }
   ],
   "source": [
    "force_bkill_dask()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
